- &qwen3-4b-official
  url: "github:Galygious/Localai/qwen3-4b-official.yaml@main"
  name: "qwen3-4b-instruct-2507-official"
  license: "Apache 2.0"
  tags:
    - gguf
    - qwen3
    - text-to-text
    - instruction-following
    - multilingual
    - reasoning
    - coding
    - tool-usage
    - cpu
    - gpu
  icon: "https://cdn-avatars.huggingface.co/v1/production/uploads/1664629393395-5e4f2c6b02b93dd21a8cd8dd.png"
  urls:
    - https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507
    - https://huggingface.co/bartowski/Qwen_Qwen3-4B-Instruct-2507-GGUF
  description: |
    **Official Qwen3-4B-Instruct-2507** - The latest and most advanced 4B instruction-tuned model from Alibaba Cloud.
    
    **Key Improvements:**
    - Significant improvements in instruction following, logical reasoning, text comprehension, mathematics, science, coding and tool usage
    - Substantial gains in long-tail knowledge coverage across multiple languages  
    - Markedly better alignment with user preferences in subjective and open-ended tasks
    - Enhanced capabilities in 256K long-context understanding
    - Native support for 262,144 tokens context length
    
    **Performance Highlights:**
    - AIME25: 47.4% (vs 19.1% previous version)
    - Arena-Hard v2: 43.4% (vs 9.5% previous version)  
    - Creative Writing v3: 83.5% (vs 53.6% previous version)
    - ZebraLogic: 80.2% (vs 35.2% previous version)
    
    Perfect for n8n workflows, creative writing, reasoning tasks, and complex instruction following.
  overrides:
    backend: vulkan-llama-cpp
    parameters:
      model: Qwen_Qwen3-4B-Instruct-2507-Q4_K_M.gguf
      backend: vulkan-llama-cpp
      temperature: 0.7
      top_p: 0.8
      top_k: 20
      context_size: 32768
      gpu_layers: 35
  files:
    - filename: Qwen_Qwen3-4B-Instruct-2507-Q4_K_M.gguf
      sha256: ""
      uri: huggingface://bartowski/Qwen_Qwen3-4B-Instruct-2507-GGUF/Qwen_Qwen3-4B-Instruct-2507-Q4_K_M.gguf
