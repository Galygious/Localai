---
- &ernie
  url: "github:mudler/LocalAI/gallery/chatml.yaml@master"
  name: "baidu_ernie-4.5-21b-a3b-thinking"
  license: apache-2.0
  tags:
    - gguf
    - GPU
    - CPU
    - text-to-text
  icon: https://cdn-avatars.huggingface.co/v1/production/uploads/64f187a2cc1c03340ac30498/TYYUxK8xD1AxExFMWqbZD.png
  urls:
    - https://huggingface.co/baidu/ERNIE-4.5-21B-A3B-Thinking
    - https://huggingface.co/bartowski/baidu_ERNIE-4.5-21B-A3B-Thinking-GGUF
  description: |
    Over the past three months, we have continued to scale the thinking capability of ERNIE-4.5-21B-A3B, improving both the quality and depth of reasoning, thereby advancing the competitiveness of ERNIE lightweight models in complex reasoning tasks. We are pleased to introduce ERNIE-4.5-21B-A3B-Thinking, featuring the following key enhancements:
    Significantly improved performance on reasoning tasks, including logical reasoning, mathematics, science, coding, text generation, and academic benchmarks that typically require human expertise.
    Efficient tool usage capabilities.
    Enhanced 128K long-context understanding capabilities.
    Note: This version has an increased thinking length. We strongly recommend its use in highly complex reasoning tasks. ERNIE-4.5-21B-A3B-Thinking is a text MoE post-trained model, with 21B total parameters and 3B activated parameters for each token.
  overrides:
    parameters:
      model: baidu_ERNIE-4.5-21B-A3B-Thinking-Q4_K_M.gguf
  files:
    - filename: baidu_ERNIE-4.5-21B-A3B-Thinking-Q4_K_M.gguf
      sha256: f309f225c413324c585e74ce28c55e76dec25340156374551d39707fc2966840
      uri: huggingface://bartowski/baidu_ERNIE-4.5-21B-A3B-Thinking-GGUF/baidu_ERNIE-4.5-21B-A3B-Thinking-Q4_K_M.gguf
- &mimo
  license: mit
  tags:
    - gguf
    - GPU
    - CPU
    - text-to-text
  icon: https://cdn-uploads.huggingface.co/production/uploads/634262af8d8089ebaefd410e/9Bnn2AnIjfQFWBGkhDNmI.png
  name: "aurore-reveil_koto-small-7b-it"
  urls:
    - https://huggingface.co/Aurore-Reveil/Koto-Small-7B-IT
    - https://huggingface.co/bartowski/Aurore-Reveil_Koto-Small-7B-IT-GGUF
  description: |
    Koto-Small-7B-IT is an instruct-tuned version of Koto-Small-7B-PT, which was trained on MiMo-7B-Base for almost a billion tokens of creative-writing data. This model is meant for roleplaying and instruct usecases.
  overrides:
    parameters:
      model: Aurore-Reveil_Koto-Small-7B-IT-Q4_K_M.gguf
  files:
    - filename: Aurore-Reveil_Koto-Small-7B-IT-Q4_K_M.gguf
      sha256: c5c38bfa5d8d5100e91a2e0050a0b2f3e082cd4bfd423cb527abc3b6f1ae180c
      uri: huggingface://bartowski/Aurore-Reveil_Koto-Small-7B-IT-GGUF/Aurore-Reveil_Koto-Small-7B-IT-Q4_K_M.gguf
- &internvl35
  name: "opengvlab_internvl3_5-30b-a3b"
  url: "github:mudler/LocalAI/gallery/qwen3.yaml@master"
  icon: https://cdn-uploads.huggingface.co/production/uploads/64006c09330a45b03605bba3/zJsd2hqd3EevgXo6fNgC-.png
  urls:
    - https://huggingface.co/OpenGVLab/InternVL3_5-30B-A3B
    - https://huggingface.co/bartowski/OpenGVLab_InternVL3_5-30B-A3B-GGUF
  license: apache-2.0
  tags:
    - multimodal
    - gguf
    - GPU
    - Cpu
    - image-to-text
    - text-to-text
  description: |
    We introduce InternVL3.5, a new family of open-source multimodal models that significantly advances versatility, reasoning capability, and inference efficiency along the InternVL series. A key innovation is the Cascade Reinforcement Learning (Cascade RL) framework, which enhances reasoning through a two-stage process: offline RL for stable convergence and online RL for refined alignment. This coarse-to-fine training strategy leads to substantial improvements on downstream reasoning tasks, e.g., MMMU and MathVista. To optimize efficiency, we propose a Visual Resolution Router (ViR) that dynamically adjusts the resolution of visual tokens without compromising performance. Coupled with ViR, our Decoupled Vision-Language Deployment (DvD) strategy separates the vision encoder and language model across different GPUs, effectively balancing computational load. These contributions collectively enable InternVL3.5 to achieve up to a +16.0% gain in overall reasoning performance and a 4.05 ×\times× inference speedup compared to its predecessor, i.e., InternVL3. In addition, InternVL3.5 supports novel capabilities such as GUI interaction and embodied agency. Notably, our largest model, i.e., InternVL3.5-241B-A28B, attains state-of-the-art results among open-source MLLMs across general multimodal, reasoning, text, and agentic tasks—narrowing the performance gap with leading commercial models like GPT-5. All models and code are publicly released.
  overrides:
    parameters:
      model: OpenGVLab_InternVL3_5-30B-A3B-Q4_K_M.gguf
    mmproj: mmproj-OpenGVLab_InternVL3_5-30B-A3B-f16.gguf
  files:
    - filename: OpenGVLab_InternVL3_5-30B-A3B-Q4_K_M.gguf
      sha256: c352004ac811cf9aa198e11f698ebd5fd3c49b483cb31a2b081fb415dd8347c2
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-30B-A3B-GGUF/OpenGVLab_InternVL3_5-30B-A3B-Q4_K_M.gguf
    - filename: mmproj-OpenGVLab_InternVL3_5-30B-A3B-f16.gguf
      sha256: fa362a7396c3dddecf6f9a714144ed86207211d6c68ef39ea0d7dfe21b969b8d
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-30B-A3B-GGUF/mmproj-OpenGVLab_InternVL3_5-30B-A3B-f16.gguf
- !!merge <<: *internvl35
  name: "opengvlab_internvl3_5-30b-a3b-q8_0"
  urls:
    - https://huggingface.co/OpenGVLab/InternVL3_5-30B-A3B
    - https://huggingface.co/bartowski/OpenGVLab_InternVL3_5-30B-A3B-GGUF
  overrides:
    parameters:
      model: OpenGVLab_InternVL3_5-30B-A3B-Q8_0.gguf
    mmproj: mmproj-OpenGVLab_InternVL3_5-30B-A3B-f16.gguf
  files:
    - filename: OpenGVLab_InternVL3_5-30B-A3B-Q8_0.gguf
      sha256: 79ac13df1d3f784cd5702b2835ede749cdfd274f141d1e0df25581af2a2a6720
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-30B-A3B-GGUF/OpenGVLab_InternVL3_5-30B-A3B-Q8_0.gguf
    - filename: mmproj-OpenGVLab_InternVL3_5-30B-A3B-f16.gguf
      sha256: fa362a7396c3dddecf6f9a714144ed86207211d6c68ef39ea0d7dfe21b969b8d
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-30B-A3B-GGUF/mmproj-OpenGVLab_InternVL3_5-30B-A3B-f16.gguf
- !!merge <<: *internvl35
  name: "opengvlab_internvl3_5-14b-q8_0"
  urls:
    - https://huggingface.co/OpenGVLab/InternVL3_5-14B
    - https://huggingface.co/bartowski/OpenGVLab_InternVL3_5-14B-GGUF
  overrides:
    parameters:
      model: OpenGVLab_InternVL3_5-14B-Q8_0.gguf
    mmproj: mmproj-OpenGVLab_InternVL3_5-14B-f16.gguf
  files:
    - filename: OpenGVLab_InternVL3_5-14B-Q8_0.gguf
      sha256: e097b9c837347ec8050f9ed95410d1001030a4701eb9551c1be04793af16677a
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-14B-GGUF/OpenGVLab_InternVL3_5-14B-Q8_0.gguf
    - filename: mmproj-OpenGVLab_InternVL3_5-14B-f16.gguf
      sha256: c9625c981969d267052464e2d345f8ff5bc7e841871f5284a2bd972461c7356d
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-14B-GGUF/mmproj-OpenGVLab_InternVL3_5-14B-f16.gguf
- !!merge <<: *internvl35
  name: "opengvlab_internvl3_5-14b"
  urls:
    - https://huggingface.co/OpenGVLab/InternVL3_5-14B
    - https://huggingface.co/bartowski/OpenGVLab_InternVL3_5-14B-GGUF
  overrides:
    mmproj: mmproj-OpenGVLab_InternVL3_5-14B-f16.gguf
    parameters:
      model: OpenGVLab_InternVL3_5-14B-Q4_K_M.gguf
  files:
    - filename: OpenGVLab_InternVL3_5-14B-Q4_K_M.gguf
      sha256: 5bb86ab56ee543bb72ba0cab58658ecb54713504f1bc9d1d075d202a35419032
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-14B-GGUF/OpenGVLab_InternVL3_5-14B-Q4_K_M.gguf
    - filename: mmproj-OpenGVLab_InternVL3_5-14B-f16.gguf
      sha256: c9625c981969d267052464e2d345f8ff5bc7e841871f5284a2bd972461c7356d
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-14B-GGUF/mmproj-OpenGVLab_InternVL3_5-14B-f16.gguf
- !!merge <<: *internvl35
  name: "opengvlab_internvl3_5-8b"
  urls:
    - https://huggingface.co/OpenGVLab/InternVL3_5-8B
    - https://huggingface.co/bartowski/OpenGVLab_InternVL3_5-8B-GGUF
  overrides:
    mmproj: mmproj-OpenGVLab_InternVL3_5-8B-f16.gguf
    parameters:
      model: OpenGVLab_InternVL3_5-8B-Q4_K_M.gguf
  files:
    - filename: OpenGVLab_InternVL3_5-8B-Q4_K_M.gguf
      sha256: f3792d241a77a88be986445fed2498489e7360947ae4556e58cb0833e9fbc697
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-8B-GGUF/OpenGVLab_InternVL3_5-8B-Q4_K_M.gguf
    - filename: mmproj-OpenGVLab_InternVL3_5-8B-f16.gguf
      sha256: 212cc090f81ea2981b870186d4b424fae69489a5313a14e52ffdb2e877852389
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-8B-GGUF/mmproj-OpenGVLab_InternVL3_5-8B-f16.gguf
- !!merge <<: *internvl35
  name: "opengvlab_internvl3_5-8b-q8_0"
  urls:
    - https://huggingface.co/OpenGVLab/InternVL3_5-8B
    - https://huggingface.co/bartowski/OpenGVLab_InternVL3_5-8B-GGUF
  overrides:
    mmproj: mmproj-OpenGVLab_InternVL3_5-8B-f16.gguf
    parameters:
      model: OpenGVLab_InternVL3_5-8B-Q8_0.gguf
  files:
    - filename: OpenGVLab_InternVL3_5-8B-Q8_0.gguf
      sha256: d81138703d9a641485c8bb064faa87f18cbc2adc9975bbedd20ab21dc7318260
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-8B-GGUF/OpenGVLab_InternVL3_5-8B-Q8_0.gguf
    - filename: mmproj-OpenGVLab_InternVL3_5-8B-f16.gguf
      sha256: 212cc090f81ea2981b870186d4b424fae69489a5313a14e52ffdb2e877852389
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-8B-GGUF/mmproj-OpenGVLab_InternVL3_5-8B-f16.gguf
- !!merge <<: *internvl35
  name: "opengvlab_internvl3_5-4b"
  urls:
    - https://huggingface.co/OpenGVLab/InternVL3_5-4B
    - https://huggingface.co/bartowski/OpenGVLab_InternVL3_5-4B-GGUF
  overrides:
    mmproj: mmproj-OpenGVLab_InternVL3_5-4B-f16.gguf
    parameters:
      model: OpenGVLab_InternVL3_5-4B-Q4_K_M.gguf
  files:
    - filename: OpenGVLab_InternVL3_5-4B-Q4_K_M.gguf
      sha256: 7c1612b6896ad14caa501238e72afa17a600651d0984225e3ff78b39de86099c
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-4B-GGUF/OpenGVLab_InternVL3_5-4B-Q4_K_M.gguf
    - filename: mmproj-OpenGVLab_InternVL3_5-4B-f16.gguf
      sha256: 0f9704972fcb9cb0a4f2c0f4eb7fe4f58e53ccd4b06ec17cf7a80271aa963eb7
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-8B-GGUF/mmproj-OpenGVLab_InternVL3_5-4B-f16.gguf
- !!merge <<: *internvl35
  name: "opengvlab_internvl3_5-4b-q8_0"
  urls:
    - https://huggingface.co/OpenGVLab/InternVL3_5-4B
    - https://huggingface.co/bartowski/OpenGVLab_InternVL3_5-4B-GGUF
  overrides:
    mmproj: mmproj-OpenGVLab_InternVL3_5-4B-f16.gguf
    parameters:
      model: OpenGVLab_InternVL3_5-4B-Q8_0.gguf
  files:
    - filename: OpenGVLab_InternVL3_5-4B-Q8_0.gguf
      sha256: ece87031e20486b1a4b86a0ba0f06b8b3b6eed676c8c6842e31041524489992d
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-4B-GGUF/OpenGVLab_InternVL3_5-4B-Q8_0.gguf
    - filename: mmproj-OpenGVLab_InternVL3_5-4B-f16.gguf
      sha256: 0f9704972fcb9cb0a4f2c0f4eb7fe4f58e53ccd4b06ec17cf7a80271aa963eb7
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-8B-GGUF/mmproj-OpenGVLab_InternVL3_5-4B-f16.gguf
- !!merge <<: *internvl35
  name: "opengvlab_internvl3_5-2b"
  urls:
    - https://huggingface.co/OpenGVLab/InternVL3_5-2B
    - https://huggingface.co/bartowski/OpenGVLab_InternVL3_5-2B-GGUF
  overrides:
    mmproj: mmproj-OpenGVLab_InternVL3_5-2B-f16.gguf
    parameters:
      model: OpenGVLab_InternVL3_5-2B-Q8_0.gguf
  files:
    - filename: OpenGVLab_InternVL3_5-2B-Q8_0.gguf
      sha256: 6997c6e3a1fe5920ac1429a21a3ec15d545e14eb695ee3656834859e617800b5
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-2B-GGUF/OpenGVLab_InternVL3_5-2B-Q8_0.gguf
    - filename: mmproj-OpenGVLab_InternVL3_5-2B-f16.gguf
      sha256: e83ba6e675b747f7801557dc24594f43c17a7850b6129d4972d55e3e9b010359
      uri: huggingface://bartowski/OpenGVLab_InternVL3_5-8B-GGUF/mmproj-OpenGVLab_InternVL3_5-2B-f16.gguf
- &lfm2
  url: "github:mudler/LocalAI/gallery/chatml.yaml@master"
  name: "lfm2-vl-450m"
  license: lfm1.0
  tags:
    - multimodal
    - image-to-text
    - gguf
    - cpu
    - gpu
    - edge
  icon: https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/7_6D7rWrLxp2hb6OHSV1p.png
  urls:
    - https://huggingface.co/LiquidAI/LFM2-VL-450M
    - https://huggingface.co/LiquidAI/LFM2-VL-450M-GGUF
  description: |
    LFM2‑VL is Liquid AI's first series of multimodal models, designed to process text and images with variable resolutions. Built on the LFM2 backbone, it is optimized for low-latency and edge AI applications.
    We're releasing the weights of two post-trained checkpoints with 450M (for highly constrained devices) and 1.6B (more capable yet still lightweight) parameters.

        2× faster inference speed on GPUs compared to existing VLMs while maintaining competitive accuracy
        Flexible architecture with user-tunable speed-quality tradeoffs at inference time
        Native resolution processing up to 512×512 with intelligent patch-based handling for larger images, avoiding upscaling and distortion
  overrides:
    parameters:
      model: LFM2-VL-450M-F16.gguf
    mmproj: mmproj-LFM2-VL-450M-F16.gguf
  files:
    - filename: LFM2-VL-450M-F16.gguf
      sha256: 0197edb886bb25136b52ac47e8c75a1d51e7ba41deda7eb18e8258b193b59a3b
      uri: huggingface://LiquidAI/LFM2-VL-450M-GGUF/LFM2-VL-450M-F16.gguf
    - filename: mmproj-LFM2-VL-450M-F16.gguf
      sha256: 416a085c5c7ba0f8d02bb8326c719a6f8f2210c2641c6bf64194a57c11c76e59
      uri: huggingface://LiquidAI/LFM2-VL-450M-GGUF/mmproj-LFM2-VL-450M-F16.gguf
